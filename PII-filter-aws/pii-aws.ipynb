{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "979bf461-79bf-4edd-81ba-e3420112c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Video Frames: 100%|██████████| 640/640 [51:53<00:00,  4.86s/frame]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "#### UTIL METHODS ####\n",
    "def readImagefromS3(bucket, photo):\n",
    "    s3 = boto3.resource('s3', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "    bucket = s3.Bucket(bucket)\n",
    "    object = bucket.Object(photo)\n",
    "    response = object.get()\n",
    "    file_stream = response['Body']\n",
    "    image = Image.open(file_stream)\n",
    "    return image\n",
    "\n",
    "def readImagefromLocal(filepath):\n",
    "    image = Image.open(filepath)\n",
    "    return image\n",
    "\n",
    "def PILimageToBytes(image,form=\"PNG\"):\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    image.save(img_byte_arr, format=form)\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "    return img_byte_arr\n",
    "\n",
    "def uploadtoS3(localSourcefile, bucket, obj):\n",
    "    s3 = boto3.resource('s3', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "    s3.Bucket(bucket).upload_file(localSourcefile, obj)\n",
    "    \n",
    "def getS3ObjectURL(bucket,key):\n",
    "    s3 = boto3.client('s3', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "    url = s3.generate_presigned_url('get_object', \n",
    "                                           Params = {'Bucket': bucket, 'Key': key},ExpiresIn = 600)\n",
    "    return url\n",
    "\n",
    "def readTextfromS3(bucket,item):\n",
    "    s3 = boto3.resource('s3', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "    bucket = s3.Bucket(bucket)\n",
    "    obj = bucket.Object(item)\n",
    "    body = obj.get()['Body'].read().decode(\"utf-8\")\n",
    "    return body\n",
    "\n",
    "def readTextFromLocal(filepath):\n",
    "    f = open(filepath, \"r\")\n",
    "    body = f.read()\n",
    "    return body\n",
    "\n",
    "def saveTextToLocal(text,filepath):\n",
    "    with open(filepath, 'w+') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "def saveImageToLocal(image,filepath):\n",
    "    image.save(filepath)\n",
    "\n",
    "\n",
    "#### HElPER METHODS #####\n",
    "\n",
    "def redactPII_Text(entities, clean_text):\n",
    "    for NER in reversed(entities):\n",
    "            clean_text = clean_text[:NER['BeginOffset']] + \"[\" + NER['Type'] + \"]\" + clean_text[NER['EndOffset']:]\n",
    "    return clean_text\n",
    "\n",
    "def blurmask(image,box):\n",
    "    imgWidth, imgHeight = image.size\n",
    "    left = imgWidth * box['Left']\n",
    "    top = imgHeight * box['Top']\n",
    "    width = imgWidth * box['Width']\n",
    "    height = imgHeight * box['Height']\n",
    "\n",
    "    mask = Image.new('L', image.size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.rectangle([left,top, left + width, top + height], fill=255) \n",
    "    blurred = image.filter(ImageFilter.GaussianBlur(52))\n",
    "    image.paste(blurred, mask=mask)\n",
    "    return image\n",
    "    \n",
    "\n",
    "def blurPII_Image(image, entities, boundingbox,text):\n",
    "    \n",
    "    for NER in reversed(entities):\n",
    "            targetText = text[NER['BeginOffset']:NER['EndOffset']]\n",
    "            if targetText not in boundingbox.keys():\n",
    "                brokenstring = targetText.split(\" \")\n",
    "            else:\n",
    "                brokenstring = []\n",
    "                brokenstring.append(targetText)\n",
    "            for targetText in brokenstring:\n",
    "                if targetText not in boundingbox.keys():\n",
    "                    pass\n",
    "                else:\n",
    "                    box = boundingbox[targetText]\n",
    "                    image = blurmask(image,box)\n",
    "            \n",
    "            \n",
    "    return image\n",
    "\n",
    "def detect_pii_from_text(text, language_code=\"en\"):\n",
    "        comp_detect = boto3.client('comprehend', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "        entities =\"\"\n",
    "        try:\n",
    "            response = comp_detect.detect_pii_entities(\n",
    "                Text=text, LanguageCode=language_code)\n",
    "            entities = response['Entities']\n",
    "            \n",
    "        finally:\n",
    "            return entities\n",
    "\n",
    "def detect_text_from_image(image):\n",
    "    \n",
    "\n",
    "    client=boto3.client('rekognition', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "    \n",
    "    response=client.detect_text(Image={\n",
    "                        'Bytes': PILimageToBytes(image),\n",
    "                    })\n",
    "                        \n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    text_corpus = []\n",
    "    text_bounding_box = {}\n",
    "    for text in textDetections:\n",
    "            if text[\"Type\"] == 'WORD':\n",
    "              \n",
    "                text_corpus.append(text['DetectedText'])\n",
    "                \n",
    "                text_bounding_box[text['DetectedText']] = text[\"Geometry\"][\"BoundingBox\"]\n",
    "    final_text_corpus = \" \".join(text_corpus)\n",
    "    return final_text_corpus,text_bounding_box\n",
    "\n",
    "def detect_redact_pii_from_text(text):\n",
    "    entities = detect_pii_from_text(text)\n",
    "    clean_text = redactPII_Text(entities, text)\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect_blur_pii_from_image(image):\n",
    "    text,text_bounding_box = detect_text_from_image(image)\n",
    "    entities = detect_pii_from_text(text)\n",
    "    blurredimage = blurPII_Image(image, entities, text_bounding_box,text)\n",
    "    return blurredimage\n",
    "\n",
    "\n",
    "def detect_blur_pii_from_video(sourceVideopath,destVideoPath):\n",
    "    \n",
    "    client=boto3.client('rekognition', aws_access_key_id, aws_secret_access_key, region_name)\n",
    "    cap = cv2.VideoCapture(sourceVideopath)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count/fps\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(destVideoPath, fourcc, 30, (frame_width, frame_height))#change fps accordingly.\n",
    "    frameRate = fps\n",
    "    # Add a progress bar for processing frames\n",
    "    with tqdm(total=frame_count, desc=\"Processing Video Frames\", unit=\"frame\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            frameId = cap.get(1)  # current frame number\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to PIL format and apply PII blur if necessary\n",
    "            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            blurredimage = detect_blur_pii_from_image(image)\n",
    "            processed_frame = cv2.cvtColor(np.array(blurredimage), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Write the processed frame to the output video\n",
    "            out.write(processed_frame)\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "##### USAGE ######\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PII Content Format: Video\n",
    "Source: Local File\n",
    "\"\"\"\n",
    "\n",
    "def blur_PII_video_Local_File(sourceVideoFilePath, DestVideoFilePath, ):\n",
    "    detect_blur_pii_from_video(sourceVideoFilePath,DestVideoFilePath)\n",
    "    \n",
    "\"\"\"\n",
    "PII Content Format: Video\n",
    "Source: S3 Bucket\n",
    "\"\"\"\n",
    "    \n",
    "def blur_PII_video_S3_bucket(sourceS3bucket, sourceS3Object,destS3bucket, destS3Object):\n",
    "    sourceVideoFilePath = getS3ObjectURL(sourceS3bucket, sourceS3Object)\n",
    "    tempvideo = \"temp\"+ sourceS3Object.split(\"/\")[-1]\n",
    "    detect_blur_pii_from_video(sourceVideoFilePath,tempvideo)\n",
    "    uploadtoS3(tempvideo, destS3bucket, destS3Object)\n",
    "    os.remove(tempvideo)\n",
    "\n",
    "##### DEMO ######    \n",
    "    \n",
    "def PII_text_image_video_demo():\n",
    "    \n",
    "    s3Bucket = #add your s3 bucket\n",
    "\n",
    "   \n",
    "    ## VIDEO ##\n",
    "\n",
    "    #sourceVideoFilePath = \n",
    "    #DestVideoFilePath = \n",
    "   \n",
    "    \n",
    "    blur_PII_video_Local_File(sourceVideoFilePath, DestVideoFilePath)\n",
    "    #blur_PII_video_S3_bucket(s3Bucket, sourceS3Object,s3Bucket, destS3Object)\n",
    "    \n",
    "    \n",
    "PII_text_image_video_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3b221-1f54-4e1f-a4f6-f1de7a6cd742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
